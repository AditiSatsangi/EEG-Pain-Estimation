{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Explore EEG Pain Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set dataset path\n",
    "root = '/path/to/dataset/Analysis/segments_allstim_1000hz_v2'\n",
    "\n",
    "# Load index\n",
    "index_df = pd.read_csv(f'{root}/index.csv')\n",
    "print(\"Total epochs:\", len(index_df))\n",
    "print(index_df.head())\n",
    "\n",
    "# Basic cleaning â€” remove flagged epochs\n",
    "clean_df = index_df[index_df['reject_flag'] == False]\n",
    "print(\"Clean epochs after removing flagged:\", len(clean_df))\n",
    "\n",
    "# Distribution of pain categories\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(data=clean_df, x='rating_bin', order=clean_df['rating_bin'].value_counts().index)\n",
    "plt.title(\"Distribution of Pain Rating Bins\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Distribution of stimulus types\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=clean_df, x='stimulus_category')\n",
    "plt.title(\"Stimulus Category Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Load and visualize one EEG epoch\n",
    "example = clean_df.sample(1).iloc[0]\n",
    "npz = np.load(f\"{root}/npz/{example['path']}\")\n",
    "X = npz['X']\n",
    "ch_names = npz['ch_names']\n",
    "print(f\"Example EEG shape: {X.shape}\")\n",
    "\n",
    "# Plot signal from 5 random channels\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, ch in enumerate(np.random.choice(range(X.shape[0]), 5, replace=False)):\n",
    "    plt.plot(X[ch] + i*10, label=ch_names[ch])  # offset for visibility\n",
    "plt.title(f\"EEG Segment Example (rating_bin={example['rating_bin']})\")\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# EEG Pain Classification - End-to-end pipeline\n",
    "\n",
    "import os, gc, time, random\n",
    "from glob import glob\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# PyTorch for deep models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# For interpretability\n",
    "import shap\n",
    "try:\n",
    "    import captum\n",
    "    from captum.attr import IntegratedGradients, Saliency\n",
    "except Exception as e:\n",
    "    captum = None\n",
    "    IntegratedGradients = None\n",
    "    Saliency = None\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# ---------- USER EDIT: set dataset root ----------\n",
    "ROOT = '/path/to/dataset/Analysis/segments_allstim_1000hz_v2'  # <- change to your path\n",
    "# -------------------------------------------------\n",
    "\n",
    "# -------------- Utility functions --------------\n",
    "def load_index(root=ROOT):\n",
    "    idx = pd.read_csv(os.path.join(root, 'index.csv'))\n",
    "    return idx\n",
    "\n",
    "def load_npz_epoch(npz_path):\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    X = data['X'].astype(np.float32)  # shape: [n_channels, n_times]\n",
    "    # tmin/tmax/sfreq/ch_names maybe present\n",
    "    meta = {k: data[k] for k in data.files if k not in ['X']}\n",
    "    return X, meta\n",
    "\n",
    "# Quick look\n",
    "index_df = load_index()\n",
    "print(\"Total epochs:\", len(index_df))\n",
    "index_df.head()\n",
    "\n",
    "# -------------- Preprocess / filter metadata --------------\n",
    "# Filter policy: drop unlabeled & drop flagged epochs by default\n",
    "def prepare_metadata(df, drop_unlabeled=True, drop_flagged=True):\n",
    "    df2 = df.copy()\n",
    "    if drop_unlabeled:\n",
    "        df2 = df2[df2['rating_bin'].notna() & (df2['rating_bin'] != 'unlabeled')]\n",
    "    if drop_flagged:\n",
    "        if 'reject_flag' in df2.columns:\n",
    "            df2 = df2[df2['reject_flag'] == False]\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    return df2\n",
    "\n",
    "meta_df = prepare_metadata(index_df, drop_unlabeled=True, drop_flagged=True)\n",
    "print(\"After filtering:\", len(meta_df))\n",
    "meta_df['rating_bin'].value_counts()\n",
    "\n",
    "# -------------- Basic EDA --------------\n",
    "def plot_distributions(df):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.countplot(df['rating_bin'], order=df['rating_bin'].value_counts().index)\n",
    "    plt.title(\"rating_bin distribution\")\n",
    "    plt.show()\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.countplot(df['stimulus_category'])\n",
    "    plt.title(\"stimulus_category\")\n",
    "    plt.show()\n",
    "    # per-subject counts\n",
    "    cnt = df['participant'].value_counts()\n",
    "    plt.figure(figsize=(10,4)); sns.histplot(cnt, bins=30); plt.title(\"epochs per participant\"); plt.show()\n",
    "\n",
    "plot_distributions(meta_df)\n",
    "\n",
    "# -------------- Simple functions to extract features --------------\n",
    "# 1) Band power features (delta/theta/alpha/beta/gamma)\n",
    "from scipy.signal import welch\n",
    "\n",
    "def bandpower_features(X, sf=1000.0, bands=None):\n",
    "    # X: [n_channels, n_times]\n",
    "    if bands is None:\n",
    "        bands = {'delta':(1,4),'theta':(4,8),'alpha':(8,13),'beta':(13,30),'gamma':(30,45)}\n",
    "    n_ch = X.shape[0]\n",
    "    feats = []\n",
    "    # compute PSD via Welch for each channel\n",
    "    f, Pxx = welch(X, fs=sf, nperseg=min(1024, X.shape[1]))\n",
    "    for bname, (l,h) in bands.items():\n",
    "        # integrate PSD between l and h\n",
    "        mask = (f >= l) & (f <= h)\n",
    "        bp = Pxx[:, mask].mean(axis=1)  # mean power in band per channel\n",
    "        feats.append(bp)\n",
    "    # feats shape (#bands, n_ch) -> flatten\n",
    "    feats = np.concatenate(feats, axis=0)\n",
    "    return feats  # length = n_ch * n_bands\n",
    "\n",
    "def time_domain_feats(X):\n",
    "    # simple time-domain stats per channel\n",
    "    mu = X.mean(axis=1)\n",
    "    std = X.std(axis=1)\n",
    "    mad = np.mean(np.abs(X - mu[:,None]), axis=1)\n",
    "    return np.concatenate([mu, std, mad], axis=0)\n",
    "\n",
    "def extract_features_from_npz(path, root=ROOT):\n",
    "    X, meta = load_npz_epoch(os.path.join(root, 'npz', path))\n",
    "    sfreq = meta.get('sfreq', 1000.0).astype(float) if 'sfreq' in meta else 1000.0\n",
    "    bp = bandpower_features(X, sf=sfreq)\n",
    "    td = time_domain_feats(X)\n",
    "    feats = np.concatenate([bp, td], axis=0)\n",
    "    return feats\n",
    "\n",
    "# Test speed on small subset\n",
    "sample_paths = meta_df['path'].sample(50, random_state=SEED).values\n",
    "t0 = time.time()\n",
    "_ = [extract_features_from_npz(p) for p in sample_paths]\n",
    "print(\"Feature extraction time for 50 samples:\", time.time() - t0, \"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
